{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSO 530 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from datetime import date, datetime, time, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#### Input params ##################\n",
    "rawpath = './raw data 17-19/'\n",
    "featurepath = './engineered features 17-19/'\n",
    "cv_size = 0.3                   # proportion of dataset to be used as cross-validation set\n",
    "Nmax = 15                       # for feature at day t, we use lags from t-1, t-2, ..., t-N as features\n",
    "                                # Nmax is the maximum N we are going to test\n",
    "fontsize = 14\n",
    "ticklabelsize = 14\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_lin_reg(df, target_col, N, pred_min, offset, forecast):\n",
    "    \"\"\"\n",
    "    Given a dataframe, get prediction at timestep t using values from t-1, t-2, ..., t-N.\n",
    "    Inputs\n",
    "        df         : dataframe with the values you want to predict. Can be of any length.\n",
    "        target_col : name of the column you want to predict e.g. 'close'\n",
    "        N          : get prediction at timestep t using values from t-1, t-2, ..., t-N\n",
    "        pred_min   : all predictions should be >= pred_min\n",
    "        offset     : for df we only do predictions for df[offset:]. e.g. offset can be size of training set\n",
    "    Outputs\n",
    "        pred_list  : the predictions for target_col. np.array of length len(df)-offset.\n",
    "    \"\"\"\n",
    "    # Create linear regression object\n",
    "    regr = LinearRegression(fit_intercept=True)\n",
    "\n",
    "    pred_list = []\n",
    "\n",
    "    for i in range(offset, len(df['close'])):\n",
    "        X_train = np.array(range(len(df['close'][i-N:i]))) # e.g. [0 1 2 3 4]\n",
    "        y_train = np.array(df['close'][i-N:i]) # e.g. [2944 3088 3226 3335 3436]\n",
    "        X_train = X_train.reshape(-1, 1)     # e.g X_train = \n",
    "                                             # [[0]\n",
    "                                             #  [1]\n",
    "                                             #  [2]\n",
    "                                             #  [3]\n",
    "                                             #  [4]]\n",
    "        # X_train = np.c_[np.ones(N), X_train]              # add a column\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "    #     print X_train.shape\n",
    "    #     print y_train.shape\n",
    "    #     print 'X_train = \\n' + str(X_train)\n",
    "    #     print 'y_train = \\n' + str(y_train)\n",
    "        regr.fit(X_train, y_train)            # Train the model\n",
    "        pred = regr.predict(np.array(N+(forecast-1)).reshape(1,-1))\n",
    "    \n",
    "        pred_list.append(pred[0][0])  # Predict the footfall using the model\n",
    "    \n",
    "    # If the values are < pred_min, set it to be pred_min\n",
    "    pred_list = np.array(pred_list)\n",
    "    pred_list[pred_list < pred_min] = pred_min\n",
    "        \n",
    "    return pred_list\n",
    "\n",
    "def get_mape(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Compute mean absolute percentage error (MAPE)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "# A function to get the best training period for each stock \n",
    "def get_best_N(mapeList, threshold = 0.03): \n",
    "    '''\n",
    "    inputs\n",
    "    mapeList : a list of mean absolute percentage errors, index 0 is where N = 2\n",
    "    threshold : the threshold for how close the mape must be for N to be considered\n",
    "    outputs:\n",
    "    bestN : the maximum N that generates a mape as close as possible to the minimum\n",
    "    '''\n",
    "    min_mape = min(mapeList)\n",
    "    arr = np.array(mapeList)\n",
    "    arr = arr[arr < min_mape + threshold]\n",
    "    best_N = mapeList.index(arr[-1]) + 2\n",
    "    return(best_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor gets dataset and returns the trading dataset\n",
    "def predictor(df, cv_size = 0.3, forecast = 2, start_day = 505):\n",
    "    '''\n",
    "    Splits data into training, testing, and validation sets, \n",
    "    then returns a test set with \n",
    "    Inputs:\n",
    "    df: dataframe with time series stock prices\n",
    "    cv_size: desired size of cross-validation set\n",
    "    forecast: the number of days in advance to forecast\n",
    "    '''\n",
    "    # Split into train, cv, and test\n",
    "    trade_start = df.index[df['day'] == start_day][0]\n",
    "    cv_start = int((1-cv_size)*trade_start)\n",
    "    test = df[trade_start:].copy()\n",
    "    train = df[:cv_start].copy()\n",
    "    cv = df[cv_start:trade_start].copy()\n",
    "    train_cv = df[:trade_start].copy()\n",
    "    # Saving Lengths of the dataframes for future use\n",
    "    num_cv = len(cv)\n",
    "    num_test = len(test)\n",
    "    num_train = len(train)\n",
    "    #Finding MAPE\n",
    "    MAPE = []\n",
    "    forecast = 2\n",
    "    for N in  range(2, Nmax):\n",
    "        est_list = get_preds_lin_reg(train_cv, 'close', N, 0, num_train, forecast)\n",
    "        cv.loc[:, 'est_2day'] = est_list\n",
    "        cv['pred'] = np.nan\n",
    "        for i in range(cv_start+1, cv_start + len(cv)):\n",
    "            cv.loc[i, 'pred'] = est_list[i-cv_start-1]\n",
    "        cv.loc[cv_start,'pred'] = cv.loc[cv_start,'close']\n",
    "        MAPE.append(get_mape(cv['close'], cv['pred']))\n",
    "    N = get_best_N(MAPE)\n",
    "    # Making Predictions for training set\n",
    "    est_list = get_preds_lin_reg(train_cv, 'close', N, 0, num_train, forecast)\n",
    "    cv.loc[:, 'est_2day'] = est_list\n",
    "    cv['pred'] = np.nan\n",
    "    for i in range(cv_start+1, cv_start + len(cv)):\n",
    "        cv.loc[i, 'pred'] = est_list[i-cv_start-1]\n",
    "    cv.loc[cv_start,'pred'] = cv.loc[cv_start,'close']\n",
    "    # Getting Validation Error Metrics\n",
    "    #r2_val = r2_score(cv['close'], cv['pred'])\n",
    "    #rmse_val = math.sqrt(mean_squared_error(cv['close'], cv['pred'],))\n",
    "    #mape_val = get_mape(cv['close'], cv['pred'])\n",
    "    # Making Predictions for test set\n",
    "    est_list = get_preds_lin_reg(df, 'close', N, 0, num_train + num_cv, forecast)\n",
    "    test.loc[:, 'est_2day'] = est_list\n",
    "    test['pred'] = np.nan\n",
    "    for i in range(trade_start+1, trade_start + len(test)):\n",
    "        test.loc[i, 'pred'] = est_list[i-trade_start-1]\n",
    "    test.loc[trade_start,'pred'] = test.loc[trade_start,'close']\n",
    "    #r2_test = r2_score(cv['close'], cv['pred'])\n",
    "    #rmse_test = math.sqrt(mean_squared_error(cv['close'], cv['pred'],))\n",
    "    #mape_test = get_mape(cv['close'], cv['pred'])\n",
    "    return(test.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to load in data and create variables\n",
    "\n",
    "def merger(rawpath, featurepath, file, training_period = 10, tech_start = 16):\n",
    "    \"\"\"\n",
    "    Takes raw stock data and engineered features and\n",
    "    returns a dataframe with new engineered variables\n",
    "    \"\"\"\n",
    "    raw = pd.read_csv(rawpath + file).assign(filename=file)\n",
    "    raw['day'] = raw.index + 1\n",
    "    raw.columns = [str(x).lower().replace(' ', '_') for x in raw.columns]\n",
    "    features = pd.read_csv(featurepath + file)\n",
    "    featureCols = list(features.columns)\n",
    "    featureCols[0] = 'time'\n",
    "    features.columns = featureCols\n",
    "    data = pd.merge(raw, features, on='time', how='outer')\n",
    "    data['std_10PROClag'] = np.nan\n",
    "    for i in range(tech_start + training_period, len(data)):\n",
    "        std = data.loc[i-training_period:i-1, 'PROClag'].std()\n",
    "        data.loc[i, 'std_10PROClag'] = std\n",
    "    #data = data.iloc[16:, ].reset_index(drop = True)\n",
    "    #cols = ['day','filename', 'PROClag', 'std_10PROClag', 'volume', 'close']\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining get metric function\n",
    "def getMetric(df, day):\n",
    "    '''\n",
    "    gets the desired metric on a specified day\n",
    "    '''\n",
    "    proj_return = (df.loc[day, 'est_2day'] - df.loc[day, 'close'])/\\\n",
    "    df.loc[day, 'close']\n",
    "    #metric = proj_return/(df.loc[day, 'std_10PROClag'])\n",
    "    metric = proj_return\n",
    "    return(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade(day, cash, increment, threshold, trade_data, \n",
    "          holding, cost = 0, sell_thresh = -0.05):\n",
    "    \"\"\"\n",
    "    Trades on a specific day given a starting amount of cash,\n",
    "    A buying increment,\n",
    "    A metric threshold,\n",
    "    The day, and the dictionary of stock dataframes,\n",
    "    And a dictionary of stocks held\n",
    "    Inputs\n",
    "    day: desired trading day\n",
    "    cash: current cash level\n",
    "    increment: how much cash to invest each day\n",
    "    treshold: threshold for the chosen metric\n",
    "    trade_data: dictionary of dataframes\n",
    "    holding: dictionary of holdings for each stock\n",
    "    \"\"\"\n",
    "    metricDF = pd.DataFrame(columns=['stock', 'metric'])\n",
    "    for stock, df in trade_data.items():\n",
    "        metric = getMetric(df, day)\n",
    "        metricDF = metricDF.append({'stock': stock,\n",
    "                                    'metric': metric}, ignore_index=True)\n",
    "    metricDF = metricDF.sort_values(by='metric', ascending=False).reset_index(drop=True)\n",
    "    # choosing Stocks to buy\n",
    "    buyDF = metricDF.loc[metricDF['metric'] > threshold, ]\n",
    "    for stock in buyDF['stock']:\n",
    "        price = trade_data[stock].loc[day, 'close']\n",
    "        shares = min(increment, cash)/price\n",
    "        holding[stock] += shares\n",
    "        cash -= shares*price*(1+cost)\n",
    "    # Defining Stocks that meet Sell Condition\n",
    "    sellDF = metricDF.loc[metricDF['metric'] <= sell_thresh, ]\n",
    "    for stock in sellDF['stock']:\n",
    "        price = trade_data[stock].loc[day, 'close']\n",
    "        shares = holding[stock]\n",
    "        cash += shares * price*(1-cost)\n",
    "        holding[stock] = 0\n",
    "    return(cash, holding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_files = sorted(os.listdir('./engineered features 17-19'))\n",
    "raw_files = sorted(os.listdir('./raw data 17-19'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Stock\n",
    "# Combining Raw files and engineered features\n",
    "doc = 'SH600000.csv'\n",
    "raw = pd.read_csv(rawpath + doc)\n",
    "raw['day'] = raw.index + 1\n",
    "raw.columns = [str(x).lower().replace(' ', '_') for x in raw.columns]\n",
    "features = pd.read_csv(featurepath + doc)\n",
    "featureCols = list(features.columns)\n",
    "featureCols[0] = 'time'\n",
    "features.columns = featureCols\n",
    "fullCombo = pd.merge(raw, features, on='time', how='outer')\n",
    "# Change all column headings to be lower case, and remove spacing\n",
    "#df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]\n",
    "#df['day'] = df.index + 1\n",
    "#df.head(10)\n",
    "#df = raw.copy()\n",
    "#df.head()\n",
    "#fullCombo.iloc[16:20,]\n",
    "df = fullCombo.iloc[16: , ].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SH600000.csv', 'SH600010.csv', 'SH600015.csv', 'SH600016.csv', 'SH600018.csv']\n"
     ]
    }
   ],
   "source": [
    "# stock_files. The list of stock files we have available\n",
    "stock_files = sorted(glob(rawpath + '*.csv'))\n",
    "for i in range(len(stock_files)):\n",
    "    item = stock_files[i]\n",
    "    item = item[item.rfind('/') + 1:]\n",
    "    stock_files[i] = item\n",
    "print(stock_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>filename</th>\n",
       "      <th>day</th>\n",
       "      <th>volumelag</th>\n",
       "      <th>rsilag</th>\n",
       "      <th>fastKlag</th>\n",
       "      <th>fastDlag</th>\n",
       "      <th>ADlag</th>\n",
       "      <th>OBVlag</th>\n",
       "      <th>MA5lag</th>\n",
       "      <th>MA15lag</th>\n",
       "      <th>day5Returnlag</th>\n",
       "      <th>day15Returnlag</th>\n",
       "      <th>PROClag</th>\n",
       "      <th>std_10PROClag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day1</td>\n",
       "      <td>154.6414</td>\n",
       "      <td>159.7405</td>\n",
       "      <td>154.4560</td>\n",
       "      <td>156.9592</td>\n",
       "      <td>45036400</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day2</td>\n",
       "      <td>156.9592</td>\n",
       "      <td>158.7207</td>\n",
       "      <td>156.3102</td>\n",
       "      <td>156.5883</td>\n",
       "      <td>21043100</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day3</td>\n",
       "      <td>156.5883</td>\n",
       "      <td>158.5353</td>\n",
       "      <td>155.8467</td>\n",
       "      <td>158.4426</td>\n",
       "      <td>23335200</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Day4</td>\n",
       "      <td>158.9988</td>\n",
       "      <td>162.1510</td>\n",
       "      <td>158.9988</td>\n",
       "      <td>159.5551</td>\n",
       "      <td>33835300</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day5</td>\n",
       "      <td>159.5551</td>\n",
       "      <td>160.8530</td>\n",
       "      <td>158.6280</td>\n",
       "      <td>160.0186</td>\n",
       "      <td>29530100</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Day752</td>\n",
       "      <td>157.8890</td>\n",
       "      <td>159.6702</td>\n",
       "      <td>157.5073</td>\n",
       "      <td>158.0162</td>\n",
       "      <td>40150148</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>752</td>\n",
       "      <td>23789908.0</td>\n",
       "      <td>62.404014</td>\n",
       "      <td>0.876540</td>\n",
       "      <td>0.864197</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.846001e+09</td>\n",
       "      <td>156.36230</td>\n",
       "      <td>152.918667</td>\n",
       "      <td>2.392746</td>\n",
       "      <td>4.198110</td>\n",
       "      <td>0.080595</td>\n",
       "      <td>0.945048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>Day753</td>\n",
       "      <td>158.5252</td>\n",
       "      <td>158.5252</td>\n",
       "      <td>154.8356</td>\n",
       "      <td>155.2172</td>\n",
       "      <td>37033892</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>753</td>\n",
       "      <td>40150148.0</td>\n",
       "      <td>62.745694</td>\n",
       "      <td>0.847054</td>\n",
       "      <td>0.862597</td>\n",
       "      <td>-0.529428</td>\n",
       "      <td>1.886151e+09</td>\n",
       "      <td>157.12566</td>\n",
       "      <td>153.351233</td>\n",
       "      <td>2.390708</td>\n",
       "      <td>4.633532</td>\n",
       "      <td>0.080530</td>\n",
       "      <td>0.925471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Day754</td>\n",
       "      <td>155.3445</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>155.2172</td>\n",
       "      <td>156.2351</td>\n",
       "      <td>21671028</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>754</td>\n",
       "      <td>37033892.0</td>\n",
       "      <td>51.626945</td>\n",
       "      <td>0.588230</td>\n",
       "      <td>0.770608</td>\n",
       "      <td>-0.793148</td>\n",
       "      <td>1.849117e+09</td>\n",
       "      <td>157.30376</td>\n",
       "      <td>153.631133</td>\n",
       "      <td>-1.533547</td>\n",
       "      <td>2.866762</td>\n",
       "      <td>-1.787213</td>\n",
       "      <td>0.930669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>Day755</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>155.2172</td>\n",
       "      <td>155.7262</td>\n",
       "      <td>13678175</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>755</td>\n",
       "      <td>21671028.0</td>\n",
       "      <td>54.766169</td>\n",
       "      <td>0.658233</td>\n",
       "      <td>0.697839</td>\n",
       "      <td>0.777836</td>\n",
       "      <td>1.870788e+09</td>\n",
       "      <td>157.02386</td>\n",
       "      <td>153.987373</td>\n",
       "      <td>-0.967725</td>\n",
       "      <td>4.510676</td>\n",
       "      <td>0.653650</td>\n",
       "      <td>1.156130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Day756</td>\n",
       "      <td>155.9806</td>\n",
       "      <td>156.7440</td>\n",
       "      <td>155.5989</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>15739054</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>756</td>\n",
       "      <td>13678175.0</td>\n",
       "      <td>52.917208</td>\n",
       "      <td>0.569451</td>\n",
       "      <td>0.605305</td>\n",
       "      <td>-0.110995</td>\n",
       "      <td>1.857110e+09</td>\n",
       "      <td>156.61674</td>\n",
       "      <td>154.402987</td>\n",
       "      <td>-1.369823</td>\n",
       "      <td>2.943681</td>\n",
       "      <td>-0.326259</td>\n",
       "      <td>1.142726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time      open      high       low     close    volume      filename  \\\n",
       "0      Day1  154.6414  159.7405  154.4560  156.9592  45036400  SH600000.csv   \n",
       "1      Day2  156.9592  158.7207  156.3102  156.5883  21043100  SH600000.csv   \n",
       "2      Day3  156.5883  158.5353  155.8467  158.4426  23335200  SH600000.csv   \n",
       "3      Day4  158.9988  162.1510  158.9988  159.5551  33835300  SH600000.csv   \n",
       "4      Day5  159.5551  160.8530  158.6280  160.0186  29530100  SH600000.csv   \n",
       "..      ...       ...       ...       ...       ...       ...           ...   \n",
       "751  Day752  157.8890  159.6702  157.5073  158.0162  40150148  SH600000.csv   \n",
       "752  Day753  158.5252  158.5252  154.8356  155.2172  37033892  SH600000.csv   \n",
       "753  Day754  155.3445  156.3623  155.2172  156.2351  21671028  SH600000.csv   \n",
       "754  Day755  156.3623  156.3623  155.2172  155.7262  13678175  SH600000.csv   \n",
       "755  Day756  155.9806  156.7440  155.5989  156.3623  15739054  SH600000.csv   \n",
       "\n",
       "     day   volumelag     rsilag  fastKlag  fastDlag     ADlag        OBVlag  \\\n",
       "0      1         NaN        NaN       NaN       NaN       NaN           NaN   \n",
       "1      2         NaN        NaN       NaN       NaN       NaN           NaN   \n",
       "2      3         NaN        NaN       NaN       NaN       NaN           NaN   \n",
       "3      4         NaN        NaN       NaN       NaN       NaN           NaN   \n",
       "4      5         NaN        NaN       NaN       NaN       NaN           NaN   \n",
       "..   ...         ...        ...       ...       ...       ...           ...   \n",
       "751  752  23789908.0  62.404014  0.876540  0.864197 -0.500000  1.846001e+09   \n",
       "752  753  40150148.0  62.745694  0.847054  0.862597 -0.529428  1.886151e+09   \n",
       "753  754  37033892.0  51.626945  0.588230  0.770608 -0.793148  1.849117e+09   \n",
       "754  755  21671028.0  54.766169  0.658233  0.697839  0.777836  1.870788e+09   \n",
       "755  756  13678175.0  52.917208  0.569451  0.605305 -0.110995  1.857110e+09   \n",
       "\n",
       "        MA5lag     MA15lag  day5Returnlag  day15Returnlag   PROClag  \\\n",
       "0          NaN         NaN            NaN             NaN       NaN   \n",
       "1          NaN         NaN            NaN             NaN       NaN   \n",
       "2          NaN         NaN            NaN             NaN       NaN   \n",
       "3          NaN         NaN            NaN             NaN       NaN   \n",
       "4          NaN         NaN            NaN             NaN       NaN   \n",
       "..         ...         ...            ...             ...       ...   \n",
       "751  156.36230  152.918667       2.392746        4.198110  0.080595   \n",
       "752  157.12566  153.351233       2.390708        4.633532  0.080530   \n",
       "753  157.30376  153.631133      -1.533547        2.866762 -1.787213   \n",
       "754  157.02386  153.987373      -0.967725        4.510676  0.653650   \n",
       "755  156.61674  154.402987      -1.369823        2.943681 -0.326259   \n",
       "\n",
       "     std_10PROClag  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "..             ...  \n",
       "751       0.945048  \n",
       "752       0.925471  \n",
       "753       0.930669  \n",
       "754       1.156130  \n",
       "755       1.142726  \n",
       "\n",
       "[756 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining All Datasets into one dictionary of many datasets\n",
    "# Using merger function\n",
    "\n",
    "stock_data = {}\n",
    "for file in stock_files:\n",
    "    data = merger(rawpath, featurepath, file)\n",
    "    stock_data[file] = data\n",
    "stock_data[stock_files[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor(df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merger(rawpath, featurepath, doc).loc[10:15, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>filename</th>\n",
       "      <th>day</th>\n",
       "      <th>volumelag</th>\n",
       "      <th>rsilag</th>\n",
       "      <th>...</th>\n",
       "      <th>ADlag</th>\n",
       "      <th>OBVlag</th>\n",
       "      <th>MA5lag</th>\n",
       "      <th>MA15lag</th>\n",
       "      <th>day5Returnlag</th>\n",
       "      <th>day15Returnlag</th>\n",
       "      <th>PROClag</th>\n",
       "      <th>std_10PROClag</th>\n",
       "      <th>est_2day</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day505</td>\n",
       "      <td>132.5229</td>\n",
       "      <td>133.2632</td>\n",
       "      <td>130.6720</td>\n",
       "      <td>131.0422</td>\n",
       "      <td>24163832</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>505</td>\n",
       "      <td>19792340.0</td>\n",
       "      <td>51.756291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076866</td>\n",
       "      <td>1.523527e+09</td>\n",
       "      <td>133.18918</td>\n",
       "      <td>132.753193</td>\n",
       "      <td>-0.826427</td>\n",
       "      <td>2.857099</td>\n",
       "      <td>0.650225</td>\n",
       "      <td>1.142438</td>\n",
       "      <td>131.293393</td>\n",
       "      <td>131.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day506</td>\n",
       "      <td>131.4123</td>\n",
       "      <td>133.0164</td>\n",
       "      <td>131.0422</td>\n",
       "      <td>133.0164</td>\n",
       "      <td>19746228</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>506</td>\n",
       "      <td>24163832.0</td>\n",
       "      <td>44.678998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714264</td>\n",
       "      <td>1.499363e+09</td>\n",
       "      <td>132.52288</td>\n",
       "      <td>132.851907</td>\n",
       "      <td>-1.939036</td>\n",
       "      <td>1.142855</td>\n",
       "      <td>-1.680671</td>\n",
       "      <td>1.149565</td>\n",
       "      <td>130.601529</td>\n",
       "      <td>131.293393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day507</td>\n",
       "      <td>131.7825</td>\n",
       "      <td>133.5100</td>\n",
       "      <td>130.0550</td>\n",
       "      <td>130.4252</td>\n",
       "      <td>19451676</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>507</td>\n",
       "      <td>19746228.0</td>\n",
       "      <td>51.082213</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.519109e+09</td>\n",
       "      <td>132.39948</td>\n",
       "      <td>133.082233</td>\n",
       "      <td>0.559663</td>\n",
       "      <td>2.764487</td>\n",
       "      <td>1.495302</td>\n",
       "      <td>1.262117</td>\n",
       "      <td>131.381500</td>\n",
       "      <td>130.601529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Day508</td>\n",
       "      <td>130.6720</td>\n",
       "      <td>131.4123</td>\n",
       "      <td>130.0550</td>\n",
       "      <td>130.0550</td>\n",
       "      <td>13603633</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>508</td>\n",
       "      <td>19451676.0</td>\n",
       "      <td>43.899876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.785702</td>\n",
       "      <td>1.499658e+09</td>\n",
       "      <td>132.02930</td>\n",
       "      <td>133.148040</td>\n",
       "      <td>-1.491169</td>\n",
       "      <td>-0.094524</td>\n",
       "      <td>-1.967255</td>\n",
       "      <td>0.943816</td>\n",
       "      <td>130.597054</td>\n",
       "      <td>131.381500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day509</td>\n",
       "      <td>129.9316</td>\n",
       "      <td>130.6720</td>\n",
       "      <td>124.7492</td>\n",
       "      <td>126.4767</td>\n",
       "      <td>30069914</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>509</td>\n",
       "      <td>13603633.0</td>\n",
       "      <td>42.970300</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.486054e+09</td>\n",
       "      <td>131.56040</td>\n",
       "      <td>133.115133</td>\n",
       "      <td>-2.407416</td>\n",
       "      <td>-0.846640</td>\n",
       "      <td>-0.284244</td>\n",
       "      <td>1.046512</td>\n",
       "      <td>129.843461</td>\n",
       "      <td>130.597054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Day752</td>\n",
       "      <td>157.8890</td>\n",
       "      <td>159.6702</td>\n",
       "      <td>157.5073</td>\n",
       "      <td>158.0162</td>\n",
       "      <td>40150148</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>752</td>\n",
       "      <td>23789908.0</td>\n",
       "      <td>62.404014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.846001e+09</td>\n",
       "      <td>156.36230</td>\n",
       "      <td>152.918667</td>\n",
       "      <td>2.392746</td>\n",
       "      <td>4.198110</td>\n",
       "      <td>0.080595</td>\n",
       "      <td>0.945048</td>\n",
       "      <td>160.906157</td>\n",
       "      <td>160.156443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Day753</td>\n",
       "      <td>158.5252</td>\n",
       "      <td>158.5252</td>\n",
       "      <td>154.8356</td>\n",
       "      <td>155.2172</td>\n",
       "      <td>37033892</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>753</td>\n",
       "      <td>40150148.0</td>\n",
       "      <td>62.745694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.529428</td>\n",
       "      <td>1.886151e+09</td>\n",
       "      <td>157.12566</td>\n",
       "      <td>153.351233</td>\n",
       "      <td>2.390708</td>\n",
       "      <td>4.633532</td>\n",
       "      <td>0.080530</td>\n",
       "      <td>0.925471</td>\n",
       "      <td>161.365032</td>\n",
       "      <td>160.906157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Day754</td>\n",
       "      <td>155.3445</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>155.2172</td>\n",
       "      <td>156.2351</td>\n",
       "      <td>21671028</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>754</td>\n",
       "      <td>37033892.0</td>\n",
       "      <td>51.626945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793148</td>\n",
       "      <td>1.849117e+09</td>\n",
       "      <td>157.30376</td>\n",
       "      <td>153.631133</td>\n",
       "      <td>-1.533547</td>\n",
       "      <td>2.866762</td>\n",
       "      <td>-1.787213</td>\n",
       "      <td>0.930669</td>\n",
       "      <td>158.343343</td>\n",
       "      <td>161.365032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Day755</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>155.2172</td>\n",
       "      <td>155.7262</td>\n",
       "      <td>13678175</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>755</td>\n",
       "      <td>21671028.0</td>\n",
       "      <td>54.766169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777836</td>\n",
       "      <td>1.870788e+09</td>\n",
       "      <td>157.02386</td>\n",
       "      <td>153.987373</td>\n",
       "      <td>-0.967725</td>\n",
       "      <td>4.510676</td>\n",
       "      <td>0.653650</td>\n",
       "      <td>1.156130</td>\n",
       "      <td>156.930229</td>\n",
       "      <td>158.343343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Day756</td>\n",
       "      <td>155.9806</td>\n",
       "      <td>156.7440</td>\n",
       "      <td>155.5989</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>15739054</td>\n",
       "      <td>SH600000.csv</td>\n",
       "      <td>756</td>\n",
       "      <td>13678175.0</td>\n",
       "      <td>52.917208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110995</td>\n",
       "      <td>1.857110e+09</td>\n",
       "      <td>156.61674</td>\n",
       "      <td>154.402987</td>\n",
       "      <td>-1.369823</td>\n",
       "      <td>2.943681</td>\n",
       "      <td>-0.326259</td>\n",
       "      <td>1.142726</td>\n",
       "      <td>154.881014</td>\n",
       "      <td>156.930229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time      open      high       low     close    volume      filename  \\\n",
       "0    Day505  132.5229  133.2632  130.6720  131.0422  24163832  SH600000.csv   \n",
       "1    Day506  131.4123  133.0164  131.0422  133.0164  19746228  SH600000.csv   \n",
       "2    Day507  131.7825  133.5100  130.0550  130.4252  19451676  SH600000.csv   \n",
       "3    Day508  130.6720  131.4123  130.0550  130.0550  13603633  SH600000.csv   \n",
       "4    Day509  129.9316  130.6720  124.7492  126.4767  30069914  SH600000.csv   \n",
       "..      ...       ...       ...       ...       ...       ...           ...   \n",
       "247  Day752  157.8890  159.6702  157.5073  158.0162  40150148  SH600000.csv   \n",
       "248  Day753  158.5252  158.5252  154.8356  155.2172  37033892  SH600000.csv   \n",
       "249  Day754  155.3445  156.3623  155.2172  156.2351  21671028  SH600000.csv   \n",
       "250  Day755  156.3623  156.3623  155.2172  155.7262  13678175  SH600000.csv   \n",
       "251  Day756  155.9806  156.7440  155.5989  156.3623  15739054  SH600000.csv   \n",
       "\n",
       "     day   volumelag     rsilag  ...     ADlag        OBVlag     MA5lag  \\\n",
       "0    505  19792340.0  51.756291  ...  0.076866  1.523527e+09  133.18918   \n",
       "1    506  24163832.0  44.678998  ... -0.714264  1.499363e+09  132.52288   \n",
       "2    507  19746228.0  51.082213  ...  1.000000  1.519109e+09  132.39948   \n",
       "3    508  19451676.0  43.899876  ... -0.785702  1.499658e+09  132.02930   \n",
       "4    509  13603633.0  42.970300  ... -1.000000  1.486054e+09  131.56040   \n",
       "..   ...         ...        ...  ...       ...           ...        ...   \n",
       "247  752  23789908.0  62.404014  ... -0.500000  1.846001e+09  156.36230   \n",
       "248  753  40150148.0  62.745694  ... -0.529428  1.886151e+09  157.12566   \n",
       "249  754  37033892.0  51.626945  ... -0.793148  1.849117e+09  157.30376   \n",
       "250  755  21671028.0  54.766169  ...  0.777836  1.870788e+09  157.02386   \n",
       "251  756  13678175.0  52.917208  ... -0.110995  1.857110e+09  156.61674   \n",
       "\n",
       "        MA15lag  day5Returnlag  day15Returnlag   PROClag  std_10PROClag  \\\n",
       "0    132.753193      -0.826427        2.857099  0.650225       1.142438   \n",
       "1    132.851907      -1.939036        1.142855 -1.680671       1.149565   \n",
       "2    133.082233       0.559663        2.764487  1.495302       1.262117   \n",
       "3    133.148040      -1.491169       -0.094524 -1.967255       0.943816   \n",
       "4    133.115133      -2.407416       -0.846640 -0.284244       1.046512   \n",
       "..          ...            ...             ...       ...            ...   \n",
       "247  152.918667       2.392746        4.198110  0.080595       0.945048   \n",
       "248  153.351233       2.390708        4.633532  0.080530       0.925471   \n",
       "249  153.631133      -1.533547        2.866762 -1.787213       0.930669   \n",
       "250  153.987373      -0.967725        4.510676  0.653650       1.156130   \n",
       "251  154.402987      -1.369823        2.943681 -0.326259       1.142726   \n",
       "\n",
       "       est_2day        pred  \n",
       "0    131.293393  131.042200  \n",
       "1    130.601529  131.293393  \n",
       "2    131.381500  130.601529  \n",
       "3    130.597054  131.381500  \n",
       "4    129.843461  130.597054  \n",
       "..          ...         ...  \n",
       "247  160.906157  160.156443  \n",
       "248  161.365032  160.906157  \n",
       "249  158.343343  161.365032  \n",
       "250  156.930229  158.343343  \n",
       "251  154.881014  156.930229  \n",
       "\n",
       "[252 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_data = {}\n",
    "for file in stock_files:\n",
    "    trade_data[file] = predictor(stock_data[file])\n",
    "trade_data[stock_files[0]].loc[,['day', 'close', 'pred', 'est_2day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>close</th>\n",
       "      <th>pred</th>\n",
       "      <th>est_2day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>505</td>\n",
       "      <td>131.0422</td>\n",
       "      <td>131.042200</td>\n",
       "      <td>131.293393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>506</td>\n",
       "      <td>133.0164</td>\n",
       "      <td>131.293393</td>\n",
       "      <td>130.601529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507</td>\n",
       "      <td>130.4252</td>\n",
       "      <td>130.601529</td>\n",
       "      <td>131.381500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>508</td>\n",
       "      <td>130.0550</td>\n",
       "      <td>131.381500</td>\n",
       "      <td>130.597054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>509</td>\n",
       "      <td>126.4767</td>\n",
       "      <td>130.597054</td>\n",
       "      <td>129.843461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>752</td>\n",
       "      <td>158.0162</td>\n",
       "      <td>160.156443</td>\n",
       "      <td>160.906157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>753</td>\n",
       "      <td>155.2172</td>\n",
       "      <td>160.906157</td>\n",
       "      <td>161.365032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>754</td>\n",
       "      <td>156.2351</td>\n",
       "      <td>161.365032</td>\n",
       "      <td>158.343343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>755</td>\n",
       "      <td>155.7262</td>\n",
       "      <td>158.343343</td>\n",
       "      <td>156.930229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>756</td>\n",
       "      <td>156.3623</td>\n",
       "      <td>156.930229</td>\n",
       "      <td>154.881014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     day     close        pred    est_2day\n",
       "0    505  131.0422  131.042200  131.293393\n",
       "1    506  133.0164  131.293393  130.601529\n",
       "2    507  130.4252  130.601529  131.381500\n",
       "3    508  130.0550  131.381500  130.597054\n",
       "4    509  126.4767  130.597054  129.843461\n",
       "..   ...       ...         ...         ...\n",
       "247  752  158.0162  160.156443  160.906157\n",
       "248  753  155.2172  160.906157  161.365032\n",
       "249  754  156.2351  161.365032  158.343343\n",
       "250  755  155.7262  158.343343  156.930229\n",
       "251  756  156.3623  156.930229  154.881014\n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_data[stock_files[0]].loc[:,['day', 'close', 'pred', 'est_2day']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cash: 1182041.70\n"
     ]
    }
   ],
   "source": [
    "# Testing Function over many days and returning cash\n",
    "# Best Thresholds for now:\n",
    "# threshold = 0.02\n",
    "# sell_thresh = -0.05\n",
    "cash = 1000000\n",
    "increment = 20000\n",
    "holding = {stock: 0 for stock in stock_files}\n",
    "cost = 0.00065\n",
    "total_assets = []\n",
    "threshold = 0.02\n",
    "sell_thresh = -0.05\n",
    "#day = 0\n",
    "#cash, holding = trade(day, cash, increment, threshold, trade_data, holding, cost)\n",
    "#trade(day, cash, increment, threshold, trade_data, holding, cost)\n",
    "#  Testing function over many days\n",
    "totalDays = len(trade_data[stock_files[0]])\n",
    "for day in range(0, totalDays-1):\n",
    "    cash, holding = trade(day, cash, increment, threshold, \n",
    "                          trade_data, holding, cost, sell_thresh)\n",
    "    assets = cash\n",
    "    for stock, shares in holding.items():\n",
    "        price = trade_data[stock].loc[day, 'close']\n",
    "        assets += price*shares\n",
    "    total_assets.append(assets)\n",
    "    #print('day ', day, ':  ', cash)\n",
    "# print(cash)\n",
    "# print(holding)\n",
    "\n",
    "for stock, shares in holding.items():\n",
    "    price = trade_data[stock].loc[totalDays - 1, 'close']\n",
    "    cash += price*shares* (1-cost)\n",
    "    holding[stock] = 0\n",
    "total_assets.append(cash)\n",
    "print(f'Total cash: {cash:.2f}')\n",
    "#print(total_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:\t\t1.1013\n",
      "Total Profitable days:\t126\n"
     ]
    }
   ],
   "source": [
    "# getting of days with profit and sharpe ratio\n",
    "pnl_list = []\n",
    "for i in range(1, len(total_assets)):\n",
    "    pnl = (total_assets[i]/total_assets[i-1]) - 1\n",
    "    pnl_list.append(pnl)\n",
    "#print(pnl_list[:15])\n",
    "pnl_arr = np.array(pnl_list)\n",
    "sharpe = (np.sqrt(252) * pnl_arr.mean())/(pnl_arr.std())\n",
    "profitable_days = np.sum(pnl_arr>0)\n",
    "print(f'Sharpe Ratio:\\t\\t{sharpe:.4f}')\n",
    "print(f'Total Profitable days:\\t{profitable_days}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Function \n",
    "#cash = 1000000\n",
    "#print(cash)\n",
    "#holding = {stock: 0 for stock in stock_files}\n",
    "#trade(0, cash, increment, threshold, trade_data, holding, cost)\n",
    "#print(cash)\n",
    "#print(holding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test R-Squared:\t0.8253\n",
      "Mean Test RMSE:\t\t9.5396\n",
      "Mean Test MAPE:\t\t2.4773\n"
     ]
    }
   ],
   "source": [
    "# Getting Statistical Metrics for each dataframe\n",
    "R2 = []\n",
    "MAPE = []\n",
    "RMSE = []\n",
    "for df in trade_data.values():\n",
    "    r2 = r2_score(df['close'], df['pred'])\n",
    "    rmse = np.sqrt(mean_squared_error(df['close'], df['pred'],))\n",
    "    mape = get_mape(df['close'], df['pred'])\n",
    "    R2.append(r2); RMSE.append(rmse); MAPE.append(mape)\n",
    "print(f'Mean Test R-Squared:\\t{(sum(R2)/len(R2)):.4f}')\n",
    "print(f'Mean Test RMSE:\\t\\t{(sum(RMSE)/len(RMSE)):.4f}')\n",
    "print(f'Mean Test MAPE:\\t\\t{(sum(MAPE)/len(MAPE)):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A function to get the best training period for each stock \n",
    "# # Redefining to change the test set\n",
    "# def get_best_N(mapeList, threshold = 0.03): \n",
    "#     '''\n",
    "#     inputs\n",
    "#     mapeList : a list of mean absolute percentage errors, index 0 is where N = 2\n",
    "#     threshold : the threshold for how close the mape must be for N to be considered\n",
    "#     outputs:\n",
    "#     bestN : the maximum N that generates a mape as close as possible to the minimum\n",
    "#     '''\n",
    "#     min_mape = min(mapeList)\n",
    "#     best_N = mapeList.index(min_mape) + 2\n",
    "#     return(best_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating New Dictionary of dataframes\n",
    "# trade_data2 = {}\n",
    "# for file in stock_files:\n",
    "#     trade_data2[file] = predictor(stock_data[file])\n",
    "# trade_data2[stock_files[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting Statistical Metrics for each dataframe\n",
    "# # (New Predictions for Test)\n",
    "# R2 = []\n",
    "# MAPE = []\n",
    "# RMSE = []\n",
    "# for df in trade_data2.values():\n",
    "#     r2 = r2_score(df['close'], df['pred'])\n",
    "#     rmse = np.sqrt(mean_squared_error(df['close'], df['pred'],))\n",
    "#     mape = get_mape(df['close'], df['pred'])\n",
    "#     R2.append(r2); RMSE.append(rmse); MAPE.append(mape)\n",
    "# print(f'Mean Test R-Squared:\\t{(sum(R2)/len(R2)):.4f}')\n",
    "# print(f'Mean Test RMSE:\\t\\t{(sum(RMSE)/len(RMSE)):.4f}')\n",
    "# print(f'Mean Test MAPE:\\t\\t{(sum(MAPE)/len(MAPE)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing Function over many days and returning cash\n",
    "# # Best Thresholds for now:\n",
    "# # threshold = 0.02\n",
    "# # sell_thresh = -0.05\n",
    "# cash = 1000000\n",
    "# increment = 20000\n",
    "# holding = {stock: 0 for stock in stock_files}\n",
    "# cost = 0.00065\n",
    "# total_assets = []\n",
    "# threshold = 0.02\n",
    "# sell_thresh = -0.04\n",
    "# #  Testing function over many days\n",
    "# totalDays = len(trade_data2[stock_files[0]])\n",
    "# for threshold in [0.02, 0.03, 0.04]:\n",
    "#     for sell_thresh in [-0.05, -0.04, -0.03, 0.02, -0.01, 0, 0.01]:\n",
    "#         cash = 1000000\n",
    "#         print(cash)\n",
    "#         for day in range(0, totalDays-1):\n",
    "#             cash, holding = trade(day, cash, increment, threshold, \n",
    "#                                   trade_data2, holding, cost, sell_thresh)\n",
    "#             assets = cash\n",
    "#             for stock, shares in holding.items():\n",
    "#                 price = trade_data2[stock].loc[day, 'close']\n",
    "#                 assets += price*shares\n",
    "#             total_assets.append(assets)\n",
    "#         # Selling off at end\n",
    "#         for stock, shares in holding.items():\n",
    "#             price = trade_data2[stock].loc[totalDays - 1, 'close']\n",
    "#             cash += price*shares* (1-cost)\n",
    "#             holding[stock] = 0\n",
    "#         total_assets.append(cash)\n",
    "#         print(f'Buy: {threshold}\\t Sell: {sell_thresh}')\n",
    "#         print(f'Total cash: {cash:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy: 0.04\t Sell: -0.02\n",
      "Total cash: 996463.68\n"
     ]
    }
   ],
   "source": [
    "# Testing Function over many days and returning cash\n",
    "# Testing wth new thresholds\n",
    "# Best Thresholds for now:\n",
    "# threshold = 0.02\n",
    "# sell_thresh = -0.05\n",
    "cash = 1000000\n",
    "increment = 5000\n",
    "holding = {stock: 0 for stock in stock_files}\n",
    "#cost = 0.00065\n",
    "cost = 0\n",
    "total_assets = []\n",
    "threshold = 0.04\n",
    "sell_thresh = -0.02\n",
    "#  Testing function over many days\n",
    "totalDays = len(trade_data[stock_files[0]])\n",
    "for day in range(0, totalDays-1):\n",
    "    cash, holding = trade(day, cash, increment, threshold, \n",
    "                          trade_data, holding, cost, sell_thresh)\n",
    "    assets = cash\n",
    "    for stock, shares in holding.items():\n",
    "        price = trade_data[stock].loc[day, 'close']\n",
    "        assets += price*shares\n",
    "    total_assets.append(assets)\n",
    "# Selling off at end\n",
    "for stock, shares in holding.items():\n",
    "    price = trade_data[stock].loc[totalDays - 1, 'close']\n",
    "    cash += price*shares* (1-cost)\n",
    "    holding[stock] = 0\n",
    "total_assets.append(cash)\n",
    "print(f'Buy: {threshold}\\t Sell: {sell_thresh}')\n",
    "print(f'Total cash: {cash:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:\t\t-0.4364\n",
      "Total Profitable days:\t94\n"
     ]
    }
   ],
   "source": [
    "# getting of days with profit and sharpe ratio\n",
    "pnl_list = []\n",
    "for i in range(1, len(total_assets)):\n",
    "    pnl = (total_assets[i]/total_assets[i-1]) - 1\n",
    "    pnl_list.append(pnl)\n",
    "#print(pnl_list[:15])\n",
    "pnl_arr = np.array(pnl_list)\n",
    "sharpe = (np.sqrt(252) * pnl_arr.mean())/(pnl_arr.std())\n",
    "profitable_days = np.sum(pnl_arr>0)\n",
    "print(f'Sharpe Ratio:\\t\\t{sharpe:.4f}')\n",
    "print(f'Total Profitable days:\\t{profitable_days}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
